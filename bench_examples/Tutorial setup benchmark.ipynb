{
 "metadata": {
  "name": "",
  "signature": "sha256:29a2cc9c3e33a4cf02f45a1dbc862f9c2372aeefb770cc289c36fc354c3f85ac"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# How to run benchmarks on rdflib stores\n",
      "\n",
      "In this tutorial we will see the necessary step to run benchmarks on rdflib stores.\n",
      "This is a following to a previous work for [getting and analysing the results of some benchmarks](http://ktbs-bench.readthedocs.org/en/latest/).\n",
      "\n",
      "This document will cover: \n",
      "\n",
      "1. Loading data into a rdflib store\n",
      "\n",
      "2. Running the benchmarks on the rdflib store"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Loading data into a rdflib store\n",
      "\n",
      "First we need to import rdflib"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import rdflib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we chose to use Sleepycat as the rdflib store, so we declare the store like this"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph = rdflib.Graph(store='Sleepycat',\n",
      "                     identifier='my_benchmark')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to actually open the store"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph.open('my_sleepycat_store',\n",
      "           create=True)  # set to False if you already have created the store"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can check where we are (to know where the store will end up) with"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/vincent/projets/liris/ktbs_bench/bench_examples\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data we will put in the store are generated data from [SP2Bench](http://dbis.informatik.uni-freiburg.de/forschung/projekte/SP2B/). Archives of this data are in the `data` directory. They are named after the number of triples they contain.\n",
      "\n",
      "We will do this tutorial with the graph in `data/32000.n3`.\n",
      "\n",
      "If you haven't extracted the archives, you can do so in Python:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bz2 import BZ2File\n",
      "data = BZ2File('../data/32000.n3.bz2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "otherwise, just declare the path to the n3 file by uncommenting the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# data = '../data/32000.n3'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We put this graph into our store with (the `%time` prefix is optional):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time graph.parse(data, format='n3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 9.51 s, sys: 46.8 ms, total: 9.56 s\n",
        "Wall time: 9.67 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<Graph identifier=my_benchmark (<class 'rdflib.graph.Graph'>)>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can check that our graph now contains around 32k triples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Size of {0} graph is {1} triples\".format(graph.identifier, len(graph)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Size of my_benchmark graph is 32330 triples\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Running the benchmark on the rdflib store\n",
      "\n",
      "We are going to use [BenchManager](https://ktbs-bench-manager.readthedocs.org/en/latest/index.html) to do the benchmarks.\n",
      "\n",
      "We will measure some of the SPARQL queries defined in `bench_examples/queries.py`. So we first load the queries:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from queries import QUERIES"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we setup the benchmark with the help of *BenchManager*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ktbs_bench_manager import BenchManager\n",
      "bmgr = BenchManager()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We make our store Sleepycat as a context for BenchManager, this is simply a function decorated by `@bmgr.context` that must `yield` a rdflib graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@bmgr.context\n",
      "def sleepycat():\n",
      "    yield graph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case it is quiet simple because we already created the `graph` object previously. In more complex cases you may need to open, check, and close the graph inside the context (see [here](https://github.com/ktbs/ktbs-bench/blob/b32e8db970995c9ae0f9e92ec12769d6c93d8d8b/bench_examples/bench_queries.py#L29-L49) for an example).\n",
      "\n",
      "Now we need to setup the bench functions for our BenchManager by decorating them with `@bmgr.bench`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@bmgr.bench\n",
      "def qall(some_graph):\n",
      "    some_graph.query(QUERIES['query_all'])\n",
      "    \n",
      "@bmgr.bench\n",
      "def q1(some_graph):\n",
      "    some_graph.query(QUERIES['q1'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could go on and bench all the queries in `QUERIES` but this is not the purpose of this tutorial.\n",
      "\n",
      "We have completed the setup of BenchManager, so we can now run it and output the results in a file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bmgr.run('/tmp/my_bench.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the CSV file the columns are the context (in this case the only one we have setup, Sleepycat, but we can declare as much as we want), and the lines are the bench functions (in this case `q1` and `qall`). The intersection of a line and a column is a time result (in seconds) for one bench function against a bench context.\n",
      "\n",
      "The results for our little bench are:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat /tmp/my_bench.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "func_name,sleepycat\r",
        "\r\n",
        "q1,0.008095979690551758\r",
        "\r\n",
        "qall,0.5300509929656982\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Don't forget to close the graph ;)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Ending notes\n",
      "\n",
      "If you plan to do more advanced benchmarks on rdflib stores you should consider:\n",
      "\n",
      "- using [BenchableGraph](https://ktbs-bench-manager.readthedocs.org/en/latest/benchable_graph.html) from `ktbs_bench_manager` to have a consistent interface between different stores.\n",
      "\n",
      "- using the [`bench.py`](https://ktbs-bench.readthedocs.org/en/latest/bench.html) utility to run several defined benchmarks."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}