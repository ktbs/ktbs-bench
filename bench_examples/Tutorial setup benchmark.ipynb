{
 "metadata": {
  "name": "",
  "signature": "sha256:7768f6328f8ef69b23ceeeb5bcbc9f4333164fa9789988b98f1e47be92e8c20d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# How to run benchmarks on rdflib stores\n",
      "\n",
      "In this tutorial we will see the necessary step to run benchmarks on the rdflib stores.\n",
      "This is a following to a previous work for [getting and analysing the results of some benchmarks](http://ktbs-bench.readthedocs.org/en/latest/).\n",
      "\n",
      "This document will cover: \n",
      "\n",
      "1. Loading data into a rdflib store\n",
      "\n",
      "2. Running the benchmarks on the rdflib store"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Loading data into a rdflib store\n",
      "\n",
      "First we need to import rdflib"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import rdflib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we chose to use Sleepycat as the rdflib store, so we declare the store like this"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph = rdflib.Graph(store='Sleepycat',\n",
      "                     identifier='my_benchmark')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to actually open the store"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph.open('my_sleepycat_store',\n",
      "           create=True)  # set to False if you already have created the store"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can check where we are (to know where the store will end up) with"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/vincent/projets/liris/ktbs_bench/bench_examples\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data we will put in the store are generated data from [SP2Bench](http://dbis.informatik.uni-freiburg.de/forschung/projekte/SP2B/). Archives of this data are in the `data` directory. They are named after the number of triples they contain. The following assumes that you have extracted the archives (or at least the archive for the graph you want to put in Sleepycat).\n",
      "\n",
      "We will do this tutorial with the graph in `data/32000.n3`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = '../data/32000.n3'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We put this graph into our store with (the `%time` prefix is optional):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time graph.parse(data, format='n3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 9.33 s, sys: 46.6 ms, total: 9.38 s\n",
        "Wall time: 9.38 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<Graph identifier=my_benchmark (<class 'rdflib.graph.Graph'>)>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can check that our graph now contains around 32k triples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Size of {0} is {1} triples\".format(graph.identifier, len(graph)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Size of my_benchmark is 32330 triples\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Running the benchmark on the rdflib store\n",
      "\n",
      "We will the use the `bench.py` (in the `bin` directory) utility to run the benchmark.\n",
      "\n",
      "We will measure the SPARQL queries defined in `bench_examples/queries.py`. So we first load the queries:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from queries import QUERIES"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we setup the benchmark with the help of *BenchManager*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ktbs_bench_manager import BenchManager\n",
      "bmgr = BenchManager()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We make our store Sleepycat as a context for BenchManager, this is simply a function decorated by `@bmgr.context` that must `yield` a rdflib graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@bmgr.context\n",
      "def sleepycat():\n",
      "    yield graph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case it is quiet simple because we already created the `graph` object previously. In more complex cases you may need to put the need to open, check, and close the graph inside the context (see [here](https://github.com/ktbs/ktbs-bench/blob/b32e8db970995c9ae0f9e92ec12769d6c93d8d8b/bench_examples/bench_queries.py#L29-L49) for an example).\n",
      "\n",
      "Now we need to setup the bench functions for our BenchManager:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@bmgr.bench\n",
      "def qall(some_graph):\n",
      "    some_graph.query(QUERIES['query_all'])\n",
      "    \n",
      "@bmgr.bench\n",
      "def q1(some_graph):\n",
      "    some_graph.query(QUERIES['q1'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could go on and bench all the queries in `QUERIES` but this is not the purpose of this tutorial.\n",
      "\n",
      "We have completed the setup of BenchManager, so we can now run it and output the results in a file of choice:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bmgr.run('/tmp/my_bench.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the CSV file the columns are the context (in this case the only one we have setup, Sleepycat, but we can declare as much store as we want), and the lines are the bench functions (in this case `q1` and `qall`). The intersection of a line and a column is a time result (in seconds) for one bench function against a bench context.\n",
      "\n",
      "The results for our little bench are:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat /tmp/my_bench.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "func_name,sleepycat\r",
        "\r\n",
        "q1,0.006417989730834961\r",
        "\r\n",
        "qall,0.4561929702758789\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Don't forget to close the graph ;)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    }
   ],
   "metadata": {}
  }
 ]
}